---
title: "Our Projects"
permalink: /projects/
excerpt: "A List of Projects"
layout: categories
comments: false
---

---

<span style="color:Salmon"> Click the titles to see the details </span>

<details>
  <summary> <span style="font-size: 20px"> (2021.04~2021.11)<br>　다관절 로봇의 물리적 지능을 위한 교시학습 인공지능기술개발 </span> </summary>
  
  <div markdown="1">
<span style="font-size: 13px"> This project was conducted at <span style="color:#3399ff">Cyber Physical System Control Lab in Kyungpook National University</span> : [Link](https://cpsc-lab.github.io/)</span>
   </div>  
  
<div style="border: 1px solid black; padding: 10px; border-color: #E6E6E6; background-color: #EFFBF5;"> 
  <br>
    <span style="font-size: 30px; color:green"> 연구목표 </span><br>
    <div style="border: 1px solid black; padding: 10px; border-color: LightGray; background-color: rgba(211, 211, 211, 0.2);"> 
      <span style="font-size: 13px">
        　■ 　로봇 매니퓰레이터의 Task 적용을 위한 <span style="color:salmon"><b>힘/위치 궤적 교시학습</b></span> 시스템 구축 <br>
         　■ 　직접 교시를 통한 <span style="color:salmon"><b>사용자 의도 파악(힘/위치)</b></span>이 가능한 교시학습 알고리즘 개발 <br>
         　■ 　7축 다관절 로봇을 활용한 <span style="color:salmon"><b>실제 작업</b></span>에 대한 모방학습 알고리즘 적용 및 검증
        </span>
    </div>
    <br>
    <br>
    <span style="font-size: 30px; color:green"> 연구내용 </span><br>
    <div style="border: 1px solid black; padding: 10px; border-color: LightGray; background-color:rgba(211, 211, 211, 0.2);"> 
      <span style="font-size: 13px">
   　■ 　기존의 물리적 지능을 위한 교시학습에 대한 방법 조사 및 분석<br>
   　■ 　Task 적용 힘/위치 제어시스템을 구축 <br>
   　■ 　7축 다관절 로봇을 위한 직접 교시 환경을 구축<br>
   　■ 　다관절 로봇의 힘과 위치 정보를 이용한 교시학습 알고리즘 개발<br>
   　■ 　주어진 Task에 대한 모방학습 알고리즘 적용<br>
   　■ 　적용된 모방학습 알고리즘 성능 평가
        </span>
    </div>
<br>

**Keywords**<br>
  <span style="font-size: 13px"> Manipulator, Physical Intelligence, Human-robot cooperation, Imitation learning, Trajectory learning</span>

<p align="center">
<img height="250" src="/assets/images/ETRI2021.gif" alt="클리닝 태스크"> 
 <p style="text-align:center;">그림 1. 클리닝 태스크</p>
  <img height="270" src="/assets/images/ETRI2021_BLOCK.jpg" alt="판다로봇과 힘 센서의 통신상태">
 <p style="text-align:center;">그림 2. 판다로봇과 힘 센서의 통신상태</p>
</p>
  
  </div>
</details>
    
---

<details>
  <summary> <span style="font-size: 20px"> (2020.05~2020.11)<br>　다관절 로봇을 위한 인공지능 모방학습 기술 개발 </span> </summary>
  
  <div markdown="1">
<span style="font-size: 13px"> This project was conducted at <span style="color:#3399ff">Cyber Physical System Control Lab in Kyungpook National University</span> : [Link](https://cpsc-lab.github.io/)</span>
   </div>  
  
<div style="border: 1px solid black; padding: 10px; border-color: #E6E6E6; background-color: #EFFBF5;"> 
  <br>
    <span style="font-size: 30px; color:green"> 연구목표 </span><br>
    <div style="border: 1px solid black; padding: 10px; border-color: LightGray; background-color: rgba(211, 211, 211, 0.2);"> 
      <span style="font-size: 13px">
        　■ 　가상환경을 활용한 로봇 매니퓰레이터의 <span style="color:salmon"><b>경로 이동 모방학습방법</b></span> 개발 <br>
         　■ 　로봇의 교시 작업 시 <span style="color:salmon"><b>사용자 의도 파악(힘+경로)을 위한 모방학습 알고리즘</b></span> 개발 <br>
         　■ 　다관절 로봇의 모방학습을 이용한 <span style="color:salmon"><b>사용자 의도에 따른 접촉력 및 경로 이동작업</b></span> 적용
        </span>
    </div>
    <br>
    <br>
    <span style="font-size: 30px; color:green"> 연구내용 </span><br>
    <div style="border: 1px solid black; padding: 10px; border-color: LightGray; background-color:rgba(211, 211, 211, 0.2);"> 
      <span style="font-size: 13px">
   　■ 　기존의 다관절 로봇에 대한 모방학습방법 조사 및 분석 <br>
   　■ 　Gazebo 가상환경 기반의 매니퓰레이터를 위한 학습환경 구축 <br>
   　■ 　ROS를 이용한 로봇 제어시스템 구축<br>
   　■ 　동적 로봇에 발생하는 접촉력을 추정하기 위한 학습알고리즘 개발 <br>
   　■ 　매니퓰레이터의 접촉력 및 경로 정보를 이용한 모방학습 알고리즘 개발<br>
   　■ 　사용자 의도 파악을 위한 모방학습 알고리즘 기반의 Drawing task 수행
        </span>
    </div>
<br>

**Keywords**<br>
  <span style="font-size: 13px"> Contact Force, Imitation Learning, Trajectory Learning, Inverse Reinforcement Learning, Manipulator</span>

<p align="center">
  <img height="250" src="/assets/images/ETRI2020.gif">
   <p style="text-align:center;">그림 1. 의도를 이용한 모방학습 분류 작업 태스크에 적용</p>
</p>
<p align="center">
  <img height="250" src="/assets/images/ETRI2020-TRI.gif"> 
   <p style="text-align:center;">그림 2. 의도를 이용한 모방학습 도형 그리기 태스크에 적용</p>
  <img height="270" src="/assets/images/ETRI2020_BLOCK.JPG">
   <p style="text-align:center;">그림 3. 제안하는 모방학습 프레임워크 블록 다이어그램</p>
</p>
  
  </div>
</details>
    
---

<details>
  <summary> <span style="font-size: 20px"> (2019.03~2019.11)<br>　센서리스 매니퓰레이터의 <br>　외력 추정기 및 임피던스 제어기 설계에 대한 연구 </span> </summary>
  
  <div markdown="1">
<span style="font-size: 13px"> This project was conducted at <span style="color:#3399ff">Cyber Physical System Control Lab in Kyungpook National University</span> : [Link](https://cpsc-lab.github.io/)</span>
   </div>  
  
<div style="border: 1px solid black; padding: 10px; border-color: #E6E6E6; background-color: #EFFBF5;"> 
  <br>
    <span style="font-size: 30px; color:green"> 연구목표 </span><br>
    <div style="border: 1px solid black; padding: 10px; border-color: LightGray; background-color: rgba(211, 211, 211, 0.2);"> 
      <span style="font-size: 13px">
        　■ 　토크 센서가 없는 로봇 매니퓰레이터에 대한 수학적 모델 기반 외력 추정 알고리즘 개발 <br>
         　■ 　모델 불확실성에 강인한 센서리스 임피던스 제어 알고리즘 개발 <br>
         　■ 　7축 로봇 매니퓰레이터 대상 태스크 종속적인 임피던스 제어 타당성 검증
        </span>
    </div>
    <br>
    <br>
    <span style="font-size: 30px; color:green"> 연구내용 </span><br>
    <div style="border: 1px solid black; padding: 10px; border-color: LightGray; background-color:rgba(211, 211, 211, 0.2);"> 
      <span style="font-size: 13px">
   　■ 　기존의 임피던스 제어 방법 및 센서리스 시스템에 대한 외력 추정 방법 조사 및 분석  <br>
   　■ 　ROS 기반 로봇 제어 시스템 구축 <br>
   　■ 　로봇 매니퓰레이터 모델링<br>
   　■ 　힘 센서리스 시스템 의 엔드 이펙터에 발생하는 외력 검출기 설계 <br>
   　■ 　모델 불확실성에 강인한 임피던스 제어기 설계<br>
   　■ 　외력 검출기 기반의 임피던스 제어기 성능 평가<br>
   　■ 　주어진 테스크에 대한 인간-로봇 협업 제어 시스템 구축
        </span>
    </div>
<br>

**Keywords**<br>
  <span style="font-size: 13px"> Manipulator, Sensorless system, Force estimator, Impedance control, Human-robot cooperation</span>

<p align="center">
  <img height="250" src="/assets/images/manipulator/force-estimation.gif">
   <p style="text-align:center;">그림 1. 외력추정 태스크</p>
</p>
  
  </div>
</details>
    
---

<details>
  <summary> <span style="font-size: 20px"> (2018.06~2018.11)<br>　2018 R-BIZ challenge  터틀봇3 오토레이스 </span> </summary>
  <div markdown="1">
<span style="font-size: 13px"> This project was conducted at <span style="color:#3399ff">Cyber Physical System Control Lab in Kyungpook National University</span> : [Link](https://cpsc-lab.github.io/)</span>
<br>
<p style="font-size:1rem;font-weight:400" onContextMenu="return false;" onselectstart="return false" ondragstart="return false">
　Turtlebot3는 다양한 미션을 자율주행을 통해 수행하기 위해 ROS 기반으로 개발되었다. 로봇의 제어를 Lyapunov function을 이용하여 안정성을 검증하였고, Matlab Computer Vision Toolbox를 이용하여 Object Dection을 구현하였다. 모든 System은 Python으로 구현되었으며 2018 R-BIZ challenge  터틀봇3 오토레이스에서 Mathworks 특별상을 수상했다. </p>


***Keywords***: Autonomous Vehicle, Visual servoing, Multi-Channel LiDAR , Sensor Fusion

<p align="center">
  <img height="250" src="/assets/images/turtlebot/racing.gif">
   <p style="text-align:center;">그림 1. 대회주행 영상</p>
</p>
  
  </div>
</details>
    
---

<details>
  <summary> <span style="font-size: 20px"> (2018.03~2018.11)<br>　다중주기 센서융합 기반 이동체 실시간 예측 제어 연구 </span> </summary>
  
  <div markdown="1">
<span style="font-size: 13px"> This project was conducted at <span style="color:#3399ff">Cyber Physical System Control Lab in Kyungpook National University</span> : [Link](https://cpsc-lab.github.io/)</span>
   </div>  
  
<div style="border: 1px solid black; padding: 10px; border-color: #E6E6E6; background-color: #EFFBF5;"> 
  <br>
    <span style="font-size: 30px; color:green"> 연구목표 </span><br>
    <div style="border: 1px solid black; padding: 10px; border-color: LightGray; background-color: rgba(211, 211, 211, 0.2);"> 
      <span style="font-size: 13px">
        　■ 　다양한 샘플링 주기를 가지는 시스템의 안정성 및 제어 성능 향상을 위한 기법 연구 <br>
         　■ 　다중 샘플링 주기를 가지는 샘플 데이터 시스템을 위한 상태 추정기 설계 <br>
         　■ 　불확실성 및 왜란에 대응한 실시간 동작을 위한 모델 기반 예측 제어기 설계<br>
         　■ 　다른 샘플링 주기를 가진 라이다와 카메라를 이용하는 모바일 로봇을 위한 경로 추적 알고리즘 구현 및 적용
        </span>
    </div>
    <br>
    <br>
    <span style="font-size: 30px; color:green"> 연구내용 </span><br>
    <div style="border: 1px solid black; padding: 10px; border-color: LightGray; background-color:rgba(211, 211, 211, 0.2);"> 
      <span style="font-size: 13px">
   　■ 　다중주기 샘플 데이터 시스템에 대한 기존의 연구 내용 조사 및 분석 <br>
   　■ 　다중 샘플링 주기를 가지는 샘플 데이터 시스템을 위한 상태 추정기 설계를 위해 새로운 리아프노프 함수 도입 및 안정화 조건 도출<br>
   　■ 　시스템의 제한 조건과 불확실성 및 왜란을 고려하는 explicit MPC 설계<br>
   　■ 　ROS 기반의 카메라, 라이라, 모바일 로봇 제어 시스템 구축<br>
   　■ 　카메라와 라이다기반의 모바일 로봇을 위한 경로 추정 알고리즘 설계 및 구현
        </span>
    </div>
<br>

**Keywords**<br>
  <span style="font-size: 13px"> Multi-rate sampled-data system, State estimator, Explicit Model predictive control, Mobile robot, tracking control</span>

<p align="center">
  <img height="250" src="/assets/images/husky/husky-experiment.gif">
</p>
<p align="center">
  <img height="250" src="/assets/images/husky/husky-experiment2.gif"> 
</p>
  
  </div>
</details>
    
---
<details>
  <summary> <span style="font-size: 20px"> (2016.11~2019.10)<br>　영상검출오류에 강인한 예측 비주얼 서보잉 기법 개발 </span> </summary>
  
  <div markdown="1">
<span style="font-size: 13px"> This project was conducted at <span style="color:#3399ff">Cyber Physical System Control Lab in Kyungpook National University</span> : [Link](https://cpsc-lab.github.io/)</span>
   </div>  
  
<div style="border: 1px solid black; padding: 10px; border-color: #E6E6E6; background-color: #EFFBF5;"> 
  <br>
    <span style="font-size: 30px; color:green"> 연구목표 </span><br>
    <div style="border: 1px solid black; padding: 10px; border-color: LightGray; background-color: rgba(211, 211, 211, 0.2);"> 
      <span style="font-size: 13px">
        　■ 　Robot manipulator에 대해 Visual servoing 시스템을 구축하고 카메라의 이미지 처리를 통해 target 목표를 이미지로부터 추출(featuring) 후 추출된 이미지로부터 목표점을 구하고, 이를 목표치와 비교해 에러를 최소화하는 예측제어 프레임웍 구축 및 6축 로봇에 적용하여 그 안정성과 성능을 확인한다. <br>
         　■ 　2차년도 연구목표는 영상인식오류에 대한 이벤트 트리거 예측 Visual servoing 방법을 제안하는데 있다. 비주얼 서보잉 시스템을 샘플데이타 방식으로 모델링하고 이에 대해 샘플링, 양자화, 데이터 오류처리 문제를 실제적인 환경에서 고려해 이에 대한 해석을 통해 영상신호처리 및 모델예측제어기 설계를 체계적으로 연구하는데 있다. 해당 연구를 바탕으로 모바일 로봇에 Visual servoing 방법을 적용하는 것을 목표로 한다.   <br>
         　■ 　강인한 예측 Visual servoing 시스템에 대한 연구결과를 바탕으로 자율 주행 자동차 시스템에 적용한다. 기존의 자율 주행 자동차 연구의 경우, 고전적인 제어방식으로 전후방 차량감지 및 주변 환경을 감지하기 위해 추가적인 센서를 장착하고 이를 바탕으로 제어하는 방법을 사용한다. 해당 연구에서는 기존 연구를 활용하여 인간이 자동차 운전을 하는 방법과 같이 백미러와, 전방, 좌우 사이드미러의 이미지를 기반으로 정속주행과 조향제어가 가능한 자율주행 방법을 개발하는데 중점을 둔다.
        </span>
    </div>
    <br>
    <br>
    <span style="font-size: 30px; color:green"> 연구내용 </span><br>
    <div style="border: 1px solid black; padding: 10px; border-color: LightGray; background-color:rgba(211, 211, 211, 0.2);"> 
      <span style="font-size: 13px">
   　Visual servo control refers to the use of computer vision data to control the motion of a robot. The vision data may be acquired from a camera that is mounted directly on a robot manipulator or on a mobile robot, in which case motion of the robot induces camera motion, or the camera can be fixed in the workspace so that it can observe the robot motion from a stationary configuration. Other configurations can be considered such as, for instance, several cameras mounted on pan-tilt heads observing the robot motion.
        </span>
    </div>
<br>

**Keywords**<br>
  <span style="font-size: 13px"> Multi-rate sampled-data system, State estimator, Explicit Model predictive control, Mobile robot, tracking control</span>

<p align="center">
  <img height="250" src="/assets/images/husky/husky-experiment.gif">
</p>
<p align="center">
  <img height="250" src="/assets/images/husky/husky-experiment2.gif"> 
</p>
  
  </div>
</details>
   
---
