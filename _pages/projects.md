---
title: "Our Projects"
permalink: /projects/
excerpt: "A List of Projects"
layout: categories
comments: false
---

---

<span style="color:Salmon"> Click the titles to see the details </span>

<details>
  <summary> <span style="font-size: 20px"> (2021.04~2021.11)<br>　다관절 로봇의 물리적 지능을 위한 교시학습 인공지능기술개발 </span> </summary>
  
  <div markdown="1">
<span style="font-size: 13px"> This project was conducted at <span style="color:#3399ff">Cyber Physical System Control Lab in Kyungpook National University</span> : [Link](http://control.knu.ac.kr/)</span>
   </div>  
  
<div style="border: 1px solid black; padding: 10px; border-color: #E6E6E6; background-color: #EFFBF5;"> 
  <br>
    <span style="font-size: 30px; color:green"> 연구목표 </span><br>
    <div style="border: 1px solid black; padding: 10px; border-color: LightGray; background-color: rgba(211, 211, 211, 0.2);"> 
      <span style="font-size: 13px">
        　■ 　로봇 매니퓰레이터의 Task 적용을 위한 <span style="color:salmon"><b>힘/위치 궤적 교시학습</b></span> 시스템 구축 <br>
         　■ 　직접 교시를 통한 <span style="color:salmon"><b>사용자 의도 파악(힘/위치)</b></span>이 가능한 교시학습 알고리즘 개발 <br>
         　■ 　7축 다관절 로봇을 활용한 <span style="color:salmon"><b>실제 작업</b></span>에 대한 모방학습 알고리즘 적용 및 검증
        </span>
    </div>
    <br>
    <br>
    <span style="font-size: 30px; color:green"> 연구내용 </span><br>
    <div style="border: 1px solid black; padding: 10px; border-color: LightGray; background-color:rgba(211, 211, 211, 0.2);"> 
      <span style="font-size: 13px">
   　■ 　기존의 물리적 지능을 위한 교시학습에 대한 방법 조사 및 분석<br>
   　■ 　Task 적용 힘/위치 제어시스템을 구축 <br>
   　■ 　7축 다관절 로봇을 위한 직접 교시 환경을 구축<br>
   　■ 　다관절 로봇의 힘과 위치 정보를 이용한 교시학습 알고리즘 개발<br>
   　■ 　주어진 Task에 대한 모방학습 알고리즘 적용<br>
   　■ 　적용된 모방학습 알고리즘 성능 평가
        </span>
    </div>
<br>

**Keywords**<br>
  <span style="font-size: 13px"> Manipulator, Physical Intelligence, Human-robot cooperation, Imitation learning, Trajectory learning</span>

<p align="center">
<img height="250" src="/assets/images/ETRI2021.gif" alt="클리닝 태스크"> 
 <p style="text-align:center;">그림 1. 클리닝 태스크</p>
  <img height="270" src="/assets/images/ETRI2021_BLOCK.jpg" alt="판다로봇과 힘 센서의 통신상태">
 <p style="text-align:center;">그림 2. 판다로봇과 힘 센서의 통신상태</p>
</p>
  
  </div>
</details>
    
---

<details>
  <summary> <span style="font-size: 20px"> (2020.05~2020.11)<br>　다관절 로봇을 위한 인공지능 모방학습 기술 개발 </span> </summary>
  
  <div markdown="1">
<span style="font-size: 13px"> This project was conducted at <span style="color:#3399ff">Cyber Physical System Control Lab in Kyungpook National University</span> : [Link](http://control.knu.ac.kr/)</span>
   </div>  
  
<div style="border: 1px solid black; padding: 10px; border-color: #E6E6E6; background-color: #EFFBF5;"> 
  <br>
    <span style="font-size: 30px; color:green"> 연구목표 </span><br>
    <div style="border: 1px solid black; padding: 10px; border-color: LightGray; background-color: rgba(211, 211, 211, 0.2);"> 
      <span style="font-size: 13px">
        　■ 　가상환경을 활용한 로봇 매니퓰레이터의 <span style="color:salmon"><b>경로 이동 모방학습방법</b></span> 개발 <br>
         　■ 　로봇의 교시 작업 시 <span style="color:salmon"><b>사용자 의도 파악(힘+경로)을 위한 모방학습 알고리즘</b></span> 개발 <br>
         　■ 　다관절 로봇의 모방학습을 이용한 <span style="color:salmon"><b>사용자 의도에 따른 접촉력 및 경로 이동작업</b></span> 적용
        </span>
    </div>
    <br>
    <br>
    <span style="font-size: 30px; color:green"> 연구내용 </span><br>
    <div style="border: 1px solid black; padding: 10px; border-color: LightGray; background-color:rgba(211, 211, 211, 0.2);"> 
      <span style="font-size: 13px">
   　■ 　기존의 다관절 로봇에 대한 모방학습방법 조사 및 분석 <br>
   　■ 　Gazebo 가상환경 기반의 매니퓰레이터를 위한 학습환경 구축 <br>
   　■ 　ROS를 이용한 로봇 제어시스템 구축<br>
   　■ 　동적 로봇에 발생하는 접촉력을 추정하기 위한 학습알고리즘 개발 <br>
   　■ 　매니퓰레이터의 접촉력 및 경로 정보를 이용한 모방학습 알고리즘 개발<br>
   　■ 　사용자 의도 파악을 위한 모방학습 알고리즘 기반의 Drawing task 수행
        </span>
    </div>
<br>

**Keywords**<br>
  <span style="font-size: 13px"> Contact Force, Imitation Learning, Trajectory Learning, Inverse Reinforcement Learning, Manipulator</span>

<p align="center">
  <img height="250" src="/assets/images/ETRI2020.gif">
   <p style="text-align:center;">그림 1. 의도를 이용한 모방학습 분류 작업 태스크에 적용</p>
</p>
<p align="center">
  <img height="250" src="/assets/images/ETRI2020-TRI.gif"> 
   <p style="text-align:center;">그림 2. 의도를 이용한 모방학습 도형 그리기 태스크에 적용</p>
  <img height="270" src="/assets/images/ETRI2020_BLOCK.JPG">
   <p style="text-align:center;">그림 3. 제안하는 모방학습 프레임워크 블록 다이어그램</p>
</p>
  
  </div>
</details>
    
---

<details>
  <summary> <span style="font-size: 20px"> (2019.03~2019.11)<br>　센서리스 매니퓰레이터의 <br>　외력 추정기 및 임피던스 제어기 설계에 대한 연구 </span> </summary>
  
  <div markdown="1">
<span style="font-size: 13px"> This project was conducted at <span style="color:#3399ff">Cyber Physical System Control Lab in Kyungpook National University</span> : [Link](http://control.knu.ac.kr/)</span>
   </div>  
  
<div style="border: 1px solid black; padding: 10px; border-color: #E6E6E6; background-color: #EFFBF5;"> 
  <br>
    <span style="font-size: 30px; color:green"> 연구목표 </span><br>
    <div style="border: 1px solid black; padding: 10px; border-color: LightGray; background-color: rgba(211, 211, 211, 0.2);"> 
      <span style="font-size: 13px">
        　■ 　토크 센서가 없는 로봇 매니퓰레이터에 대한 수학적 모델 기반 외력 추정 알고리즘 개발 <br>
         　■ 　모델 불확실성에 강인한 센서리스 임피던스 제어 알고리즘 개발 <br>
         　■ 　7축 로봇 매니퓰레이터 대상 태스크 종속적인 임피던스 제어 타당성 검증
        </span>
    </div>
    <br>
    <br>
    <span style="font-size: 30px; color:green"> 연구내용 </span><br>
    <div style="border: 1px solid black; padding: 10px; border-color: LightGray; background-color:rgba(211, 211, 211, 0.2);"> 
      <span style="font-size: 13px">
   　■ 　기존의 임피던스 제어 방법 및 센서리스 시스템에 대한 외력 추정 방법 조사 및 분석  <br>
   　■ 　ROS 기반 로봇 제어 시스템 구축 <br>
   　■ 　로봇 매니퓰레이터 모델링<br>
   　■ 　힘 센서리스 시스템 의 엔드 이펙터에 발생하는 외력 검출기 설계 <br>
   　■ 　모델 불확실성에 강인한 임피던스 제어기 설계<br>
   　■ 　외력 검출기 기반의 임피던스 제어기 성능 평가<br>
   　■ 　주어진 테스크에 대한 인간-로봇 협업 제어 시스템 구축
        </span>
    </div>
<br>

**Keywords**<br>
  <span style="font-size: 13px"> Contact Force, Imitation Learning, Trajectory Learning, Inverse Reinforcement Learning, Manipulator</span>

<p align="center">
  <img height="250" src="/assets/images/manipulator/force-estimation.gif">
   <p style="text-align:center;">그림 1. 외력추정 태스크</p>
</p>
  
  </div>
</details>
    
---

<details>
  <summary> <span style="font-size: 20px"> (2018.06~2018.11)<br>　2018 R-BIZ challenge  터틀봇3 오토레이스 </span> </summary>
  <div markdown="1">
This project was conducted at <span style="color:#3399ff">Cyber Physical System Control Lab in Kyungpook National University</span> : [Link](http://control.knu.ac.kr/)
  </div>  
<br>
<p style="font-size:1rem;font-weight:400" onContextMenu="return false;" onselectstart="return false" ondragstart="return false">
　Research on Unmanned Aerial Vehicles has been actively conducted in recent years. In particular, the UAV to explore an unknown, GNSS-denied environment is required, but the self-localization method, such as Visual Inertial Odometry, is mandatory to operate it. Considering the payload and the operating time of the UAV, lightweight and low-power consuming cameras and IMU are preferred, and even Object Detection and 3D Mapping can be obtained using a RGB-D camera. In this work, we developed a 3D Mapping system including object positions in an unknown and GNSS-denied environment for the UAV with a RGB-D camera. The system is demonstrated in Gazebo simulator, and the quantitative and qualitative results are obtained.</p>


***Keywords***: Autonomous Vehicle, Visual servoing, Multi-Channel LiDAR , Sensor Fusion

<p align="center">
  <img height="250" src="/assets/images/turtlebot/racing.gif">
   <p style="text-align:center;">그림 1. 대회주행 영상</p>
</p>
</details>
    
---

<details>
  <summary> <span style="font-size: 20px"> (2018.03~2018.11)<br>　다중주기 센서융합 기반 이동체 실시간 예측 제어 연구 </span> </summary>
  
  <div markdown="1">
<span style="font-size: 13px"> This project was conducted at <span style="color:#3399ff">Cyber Physical System Control Lab in Kyungpook National University</span> : [Link](http://control.knu.ac.kr/)</span>
   </div>  
  
<div style="border: 1px solid black; padding: 10px; border-color: #E6E6E6; background-color: #EFFBF5;"> 
  <br>
    <span style="font-size: 30px; color:green"> 연구목표 </span><br>
    <div style="border: 1px solid black; padding: 10px; border-color: LightGray; background-color: rgba(211, 211, 211, 0.2);"> 
      <span style="font-size: 13px">
        　■ 　다양한 샘플링 주기를 가지는 시스템의 안정성 및 제어 성능 향상을 위한 기법 연구 <br>
         　■ 　다중 샘플링 주기를 가지는 샘플 데이터 시스템을 위한 상태 추정기 설계 <br>
         　■ 　불확실성 및 왜란에 대응한 실시간 동작을 위한 모델 기반 예측 제어기 설계<br>
         　■ 　다른 샘플링 주기를 가진 라이다와 카메라를 이용하는 모바일 로봇을 위한 경로 추적 알고리즘 구현 및 적용
        </span>
    </div>
    <br>
    <br>
    <span style="font-size: 30px; color:green"> 연구내용 </span><br>
    <div style="border: 1px solid black; padding: 10px; border-color: LightGray; background-color:rgba(211, 211, 211, 0.2);"> 
      <span style="font-size: 13px">
   　■ 　다중주기 샘플 데이터 시스템에 대한 기존의 연구 내용 조사 및 분석 <br>
   　■ 　다중 샘플링 주기를 가지는 샘플 데이터 시스템을 위한 상태 추정기 설계를 위해 새로운 리아프노프 함수 도입 및 안정화 조건 도출<br>
   　■ 　시스템의 제한 조건과 불확실성 및 왜란을 고려하는 explicit MPC 설계<br>
   　■ 　ROS 기반의 카메라, 라이라, 모바일 로봇 제어 시스템 구축<br>
   　■ 　카메라와 라이다기반의 모바일 로봇을 위한 경로 추정 알고리즘 설계 및 구현
        </span>
    </div>
<br>

**Keywords**<br>
  <span style="font-size: 13px"> Contact Force, Imitation Learning, Trajectory Learning, Inverse Reinforcement Learning, Manipulator</span>

<p align="center">
  <img height="250" src="/assets/images/husky/husky-experiment.gif">
   <p style="text-align:center;">그림 1. 의도를 이용한 모방학습 분류 작업 태스크에 적용</p>
</p>
<p align="center">
  <img height="250" src="/assets/images/husky/husky-experiment2.gif"> 
   <p style="text-align:center;">그림 2. 의도를 이용한 모방학습 도형 그리기 태스크에 적용</p>
</p>
  
  </div>
</details>
    
---

<details>
  <summary> <span style="font-size: 20px"> (2016.11~2019.10)<br>　영상검출오류에 강인한 예측 비주얼 서보잉 기법 개발 </span> </summary>
  <div markdown="1">
This project was conducted at <span style="color:grin">Cyber Physical System Control Lab in Kyungpook National University</span> : [Link](http://control.knu.ac.kr/)
  </div>  
<br>
<p style="font-size:1rem;font-weight:400" onContextMenu="return false;" onselectstart="return false" ondragstart="return false">
　Visual servo control refers to the use of computer vision data to control the motion of a robot. The vision data may be acquired from a camera that is mounted directly on a robot manipulator or on a mobile robot, in which case motion of the robot induces camera motion, or the camera can be fixed in the workspace so that it can observe the robot motion from a stationary configuration. Other configurations can be considered such as, for instance, several cameras mounted on pan-tilt heads observing the robot motion.</p>

<br>

***Keywords***: Autonomous Vehicle, Visual servoing, Multi-Channel LiDAR , Sensor Fusion

<p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/j8nnk5R37XU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
    </iframe>
</p>
</details>
    
---
